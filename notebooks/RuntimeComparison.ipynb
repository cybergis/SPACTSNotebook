{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55e26587",
   "metadata": {},
   "source": [
    "## Runtime Comparison\n",
    "\n",
    "**Author:** Alex Michels\n",
    "\n",
    "In this notebook we will compare the runtime of our clustering algorithm for travel-time analysis against analyzing each hospital seperately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567d8c23",
   "metadata": {},
   "source": [
    "First, we need to load some packages for our analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34d10bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from glob import glob\n",
    "from IPython.display import display, Markdown\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a155481",
   "metadata": {},
   "source": [
    "Each method had a \"Part 1\" and \"Part 2\". \n",
    "\n",
    "* Part 1 perfomed the clustering (or not) and then submitted each hospital/cluster as a seperate job, pausing for 1 second between jobs. \n",
    "* The jobs submitted by Part 1 are the \"Part 2\" jobs. They performed the analysis (travel-time catchment) for the hospital or region assigned to them by Part 1. At the end of each Part 2 job, the job records it's index and runtime in seconds in a file\n",
    "\n",
    "The \"-1\" region index gives the time in seconds recorded by SLURM for the \"Part 1\"s (manually entered from SLURM output) and the rest are the time in seconds (recorded by the Python script). The data is at the path `/data/runtime`. The files ending with \"NM\" stands for \"no merge\" and the files ending with \"XXG\" have the records when applying SPACTS for XX gigabytes memory limit for the computation (so the SPACTS partitioning used XX/2). We ran each method 5 times, let's dig into the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd75783",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_path = \"../data/runtime/\"\n",
    "runtime_file = \"Par_Timings-{}-*.csv\"\n",
    "runtime_codes = [\"20G\", \"26G\", \"32G\", \"40G\", \"48G\", \"56G\", \"64G\", \"72G\", \"NM\"]\n",
    "runtime_globs = [time_path + runtime_file.format(x) for x in runtime_codes]\n",
    "print(runtime_globs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb6fafa",
   "metadata": {},
   "source": [
    "<hr id=\"comparison\">\n",
    "\n",
    "## Analyzing Runtimes\n",
    "\n",
    "Now that we have specified the paths, let's load the SPACTS data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aeac12",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = {}\n",
    "for code, pattern in zip(runtime_codes, runtime_globs):\n",
    "    print(pattern)\n",
    "    _files_to_load = glob(pattern)\n",
    "    print(f\"We have {len(_files_to_load)} files for code {code}\")\n",
    "    csvs[code] = []\n",
    "    for _file in _files_to_load:\n",
    "        df = pd.read_csv(_file)\n",
    "        csvs[code].append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643fa457",
   "metadata": {},
   "source": [
    "So we have a list of Dataframes. Let's preview one of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b246a3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs[code][0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fb0f8f",
   "metadata": {},
   "source": [
    "To know if we were able to speed up or not, we need to calculate the \"no merge\" (NM) average runtime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400a228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_merge_avg = np.mean([sum(df['TIME']) for df in csvs[\"NM\"]])\n",
    "print(datetime.timedelta(seconds=no_merge_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e44c94f",
   "metadata": {},
   "source": [
    "Using that information, we can now calculate a variety of summary statistics:\n",
    "\n",
    "* Mean Part 1 - the average time for the clustering/job submission step.\n",
    "* Mean Part 2 - the average time for the travel time calculation step.\n",
    "* Mean Total - the average total computing time for the method.\n",
    "* STD Total - the standard deviation for the total computing time for the method.\n",
    "* Waiting Time - the maximum Part 1 and Part 2. This is the worst-case waiting time to get results back if you could run infinite (or at least 7438) jobs at once.\n",
    "* Speed Up - the no merge average computing time divided by the average computing time for the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975e58e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table_string = \"|Method|Mean Job Submission|Mean Travel Analysis|Mean Total|STD Total|Turnaround Time|Speed Up|\\n|-|-|-|-|-|-|-|\\n\"\n",
    "for key, val in csvs.items():\n",
    "    table_string += f\"|{key}|\"\n",
    "    mean_part_1 = round(np.mean([df.loc[df['REGION_INDEX']==-1, 'TIME'].values[0] for df in val]))\n",
    "    table_string += f\"{datetime.timedelta(seconds=mean_part_1)}|\"\n",
    "    mean_part_2 = round(np.mean([sum(df.loc[df['REGION_INDEX']>-1, 'TIME']) for df in val]))\n",
    "    mean_total = round(np.mean([sum(df['TIME']) for df in val]))\n",
    "    table_string += f\"{datetime.timedelta(seconds=mean_part_2)}|\"\n",
    "    table_string += f\"{datetime.timedelta(seconds=mean_total)}|\"\n",
    "    std_total = round(np.std([sum(df['TIME']) for df in val]))\n",
    "    table_string += f\"{datetime.timedelta(seconds=std_total)}|\"\n",
    "    max_waiting_time = round(max([df.loc[df['REGION_INDEX']==-1, 'TIME'].values[0] for df in val]) + max([max(df.loc[df['REGION_INDEX']>-1, 'TIME']) for df in val]))\n",
    "    table_string += f\"{datetime.timedelta(seconds=max_waiting_time)}|\"\n",
    "    table_string += f\"{no_merge_avg/mean_total:.2f}x|\"\n",
    "    table_string += \"\\n\"\n",
    "\n",
    "display(Markdown(table_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bd5317",
   "metadata": {},
   "source": [
    "Let's make a line graph to illustrate the average computing times with standard deviation error bars. First, let's collect the information we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fe07aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbs = [int(code[:-1]) for code in runtime_codes[:-1]]\n",
    "means = [round(np.mean([sum(df['TIME']) for df in val])) / 3600.0 for key, val in csvs.items()][:-1]\n",
    "stds = [round(np.std([sum(df['TIME']) for df in val])) / 3600.0 for key, val in csvs.items()][:-1]\n",
    "gbs, means, stds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d16bb25",
   "metadata": {},
   "source": [
    "Then, we can plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c937a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "fontsize = 20\n",
    "plt.errorbar(gbs, means, yerr=stds, color='red')\n",
    "plt.xlabel(\"Memory Limit (GB)\", fontsize=fontsize)\n",
    "plt.xticks(gbs, fontsize=fontsize-4)\n",
    "plt.ylabel(\"Mean computing time (hours)\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize-4)\n",
    "ax.grid('on')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../img/Runtimes.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab31c29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
